# Data Modeling with Postgres

This is the solution to the project **Data Modeling with Postgres** of Udacity's [Data Engineering Nanodegree](https://www.udacity.com/course/data-engineer-nanodegree--nd027).

## Introduction

The purpose of this project is to empower an analytics team of a music streaming app so that particular queries regarding user activity can be made more easily. This will be achieved by building a **Postgres** database with a star schema and an ETL process to ultimately load read-optimized data into the database.

## Resources

* `test.ipynb` displays the first few rows of each table to let you check your database.
* `create_tables.py` drops and creates your tables. You run this file to reset your tables before each time you run your ETL scripts.
* `etl.ipynb` reads and processes a single file from song_data and log_data and loads the data into your tables. This notebook contains detailed instructions on the ETL process for each of the tables.
* `etl.py` reads and processes files from song_data and log_data and loads them into your tables. You can fill this out based on your work in the ETL notebook.
* `sql_queries.py` contains all your sql queries, and is imported into the last three files above.


[WIP] Discuss the purpose of this database in the context of the startup, Sparkify, and their analytical goals.

[WIP] State and justify your database schema design and ETL pipeline.

[WIP] Provide example queries and results for song play analysis.